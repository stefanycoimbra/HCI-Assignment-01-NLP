{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMSz8usrhUS5v/ZxW/Y4L3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanycoimbra/HCI-Assignment-01-NLP/blob/main/HCI_Assignment_01_Problem_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Name : Stéfany Coura Coimbra\n",
        "##Student ID : B202300194\n",
        "\n",
        "##Python Assignment of Human-Computer Interaction : Part 02"
      ],
      "metadata": {
        "id": "Db40v6lv4jM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Problem 2:** Extract all bigrams, trigrams using ngrams of nltk library\n",
        "\n",
        "#### Sentences = \"Machine learning is a necessary field in today's world. Data science can do wonders. Natural Language Processing is how machines understand text”"
      ],
      "metadata": {
        "id": "5_F-4ws95ZCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "##The approach\n",
        "To address the problem, we will be using NLTK Library with Its method ngrams. We will build a function to extract the n-grams from a text and we will text It with the given sentence."
      ],
      "metadata": {
        "id": "AmOBNG3u5cFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##Installing NLTK\n",
        "To start the task, first we need to install the NLTK Python Library so we can use the Natural Language Toolkit to do Natural Language Processing.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ddq4M6Uv5iE_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxKtb--n4KPG",
        "outputId": "a73efcf8-e2f5-480e-ace4-ef7fbfb2ef46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "##Importing the libraries"
      ],
      "metadata": {
        "id": "_aa8a3E452XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams"
      ],
      "metadata": {
        "id": "WxLglA8u5nef"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##String with the sentence to work with"
      ],
      "metadata": {
        "id": "xOQEPlZc645k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Machine learning is a necessary field in today's world. Data science can do wonders. Natural Language Processing is how machines understand text\""
      ],
      "metadata": {
        "id": "bur-G-RQ68xX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Implementing a function to extract n-grams in Python"
      ],
      "metadata": {
        "id": "5R-2v4bf6VP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# n -> the quantity of words to be extracted from the text\n",
        "# in each interaction (n-grams) by splittering the sentence\n",
        "def extract_ngrams(n):\n",
        "  n_grams = ngrams(sentence.split(), n)\n",
        "  for ng in n_grams:\n",
        "    print(ng)"
      ],
      "metadata": {
        "id": "NwxbuiGL5_CR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can test to any value for n calling extract_ngrams():"
      ],
      "metadata": {
        "id": "vpKjXDzS8zGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting bigrams"
      ],
      "metadata": {
        "id": "ckoKnX-J7rsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_ngrams(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpduQkHl7wp9",
        "outputId": "efa6fdaa-e8fc-41b2-9322-07b82ae2f319"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Machine', 'learning')\n",
            "('learning', 'is')\n",
            "('is', 'a')\n",
            "('a', 'necessary')\n",
            "('necessary', 'field')\n",
            "('field', 'in')\n",
            "('in', \"today's\")\n",
            "(\"today's\", 'world.')\n",
            "('world.', 'Data')\n",
            "('Data', 'science')\n",
            "('science', 'can')\n",
            "('can', 'do')\n",
            "('do', 'wonders.')\n",
            "('wonders.', 'Natural')\n",
            "('Natural', 'Language')\n",
            "('Language', 'Processing')\n",
            "('Processing', 'is')\n",
            "('is', 'how')\n",
            "('how', 'machines')\n",
            "('machines', 'understand')\n",
            "('understand', 'text')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting trigrams"
      ],
      "metadata": {
        "id": "_aZox9tl8Zjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_ngrams(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDdQm3X770lF",
        "outputId": "dde55dd3-ac62-49fb-8a0a-7dc60ec79bcc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Machine', 'learning', 'is')\n",
            "('learning', 'is', 'a')\n",
            "('is', 'a', 'necessary')\n",
            "('a', 'necessary', 'field')\n",
            "('necessary', 'field', 'in')\n",
            "('field', 'in', \"today's\")\n",
            "('in', \"today's\", 'world.')\n",
            "(\"today's\", 'world.', 'Data')\n",
            "('world.', 'Data', 'science')\n",
            "('Data', 'science', 'can')\n",
            "('science', 'can', 'do')\n",
            "('can', 'do', 'wonders.')\n",
            "('do', 'wonders.', 'Natural')\n",
            "('wonders.', 'Natural', 'Language')\n",
            "('Natural', 'Language', 'Processing')\n",
            "('Language', 'Processing', 'is')\n",
            "('Processing', 'is', 'how')\n",
            "('is', 'how', 'machines')\n",
            "('how', 'machines', 'understand')\n",
            "('machines', 'understand', 'text')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Final comments"
      ],
      "metadata": {
        "id": "4WRdb0Mq-L8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works! The function can be used to n = 4, n = 5, n = 6, ..., n = 22. That's because the total size of the sentence is 22 words, so doesn't make sense or logic to the function to extract more words than this value:"
      ],
      "metadata": {
        "id": "agXH_E8g9BEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_ngrams(22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9aQyVA39Knr",
        "outputId": "3260e993-250a-4d56-e092-3dba36baac95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Machine', 'learning', 'is', 'a', 'necessary', 'field', 'in', \"today's\", 'world.', 'Data', 'science', 'can', 'do', 'wonders.', 'Natural', 'Language', 'Processing', 'is', 'how', 'machines', 'understand', 'text')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It doesn't occur an error when we try n = 23, but we can't have an answer from the function either:"
      ],
      "metadata": {
        "id": "8jYab-xT-FWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_ngrams(23)"
      ],
      "metadata": {
        "id": "s--mm5Tn9M0-"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}